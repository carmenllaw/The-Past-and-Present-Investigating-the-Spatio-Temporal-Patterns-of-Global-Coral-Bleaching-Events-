rm(list=ls())

library(ncdf4)
library(raster)
library(dplyr)
library(ggplot2)
library(stringr)
library(sf)
library(nngeo)
library(purrr)
library(tibble)

#combining pastpaper cleaned data and new data from Dec 2017 onwards:
pp<-read.csv("pp_data.csv")
rc_new<-read.csv("rc_cortad_2022.csv")
rc_manual<-read.csv("rc_manual_ecoregions.csv")
final<-read.csv("final_everything_last_one.csv")

#combining rc data with ecoregions (Sully et al., 2019 - revised because of discountined package)----
rc_new<-read.csv("rc_cortad_2022.csv")
diversity<-read.csv("Coral_diversity.csv")

ECO <- st_read(
  dsn   = "ecoregions_github", 
  layer = "ecoregion_exportPolygon"
)

ECO_noholes <- st_remove_holes(ECO)
print(ECO_noholes)

#extract geometry to rc
rc_eco <- st_as_sf(rc_new, 
                  coords = c("Longitude.Degrees", "Latitude.Degrees"), 
                  crs = 4326, 
                  remove = FALSE)

rc_eco <- st_transform(rc_eco, st_crs(ECO_noholes))
rc_joined <- st_join(rc_eco, ECO_noholes[, c("ERG", "Ecoregion")])

#fix errors: 
#ECO_noholes_valid <- st_make_valid(ECO_noholes)
#rc_joined <- st_join(rc_eco, ECO_noholes_valid[, c("ECO_CODE", "ECOREGION")])

rc_joined <- rc_joined %>%
  rename(Ecoregion_code = ERG) 

rc_joined$Ecoregion <- as.character(rc_joined$Ecoregion)
diversity$ECOREGION <- as.character(diversity$ECOREGION)

rc_joined$Ecoregion <- trimws(rc_joined$Ecoregion)
diversity$ECOREGION <- trimws(diversity$ECOREGION)

rc_joined <- rc_joined %>%
  left_join(diversity, by = c("Ecoregion" = "ECOREGION"))

#check for missing data
rc_joined <- rc_joined[!rowSums(is.na(rc_joined[, c("ClimSST", "Temperature_Kelvin", "Temperature_Mean", "Temperature_Minimum", "Temperature_Maximum", 
                                      "Temperature_Kelvin_Standard_Deviation", "Windspeed",
                                      "SSTA", "SSTA_Standard_Deviation", "SSTA_Mean", "SSTA_Minimum", "SSTA_Maximum", 
                                      "SSTA_Freq", "SSTA_Freq_Standard_Deviation", "SSTA_Freq_Max", "SSTA_Freq_Mean", "SSTA_DHW", 
                                      "SSTA_DHW_Standard_Deviation", "SSTA_DHW_Max", "SSTA_DHW_Mean", 
                                      "TSA", "TSA_Standard_Deviation", "TSA_Mean", "TSA_Minimum", "TSA_Maximum", 
                                      "TSA_Freq", "TSA_Freq_Standard_Deviation", "TSA_Freq_Mean", "TSA_Freq_Max", "TSA_DHW", 
                                      "TSA_DHW_Standard_Deviation", "TSA_DHW_Max", "TSA_DHW_Mean")])), ]
sum(is.na(rc_joined$Diversity)) #586
sum(is.na(pp$Diversity)) #586

unique(rc_joined$Ecoregion)
unique(diversity$ECOREGION)

sum(rc_joined$Ecoregion %in% diversity$ECOREGION)
mismatched_ecoregions <- rc_joined$Ecoregion[!rc_joined$Ecoregion %in% diversity$ECOREGION]
unique(mismatched_ecoregions)

#manually match unmatched ecoregions:
#library(writexl)
#write_xlsx(rc_joined, "rc_joined_manual_ecoregions.xlsx")

#load manually inputted NA ecoregions: 
rc_joined<- read.csv("rc_manual_ecoregions.csv")

#further cleaning to make everything consistent 
names(rc_cortad_eco_rate)[32]<-"SSTA_Frequency"
names(rc_cortad_eco_rate)[33]<-"SSTA_Frequency_Standard_Deviation"
names(rc_cortad_eco_rate)[34]<-"SSTA_FrequencyMax"
names(rc_cortad_eco_rate)[35]<-"SSTA_FrequencyMean"
names(rc_cortad_eco_rate)[38]<-"SSTA_DHWMax"
names(rc_cortad_eco_rate)[39]<-"SSTA_DHWMean"
names(rc_cortad_eco_rate)[45]<-"TSA_Frequency"
names(rc_cortad_eco_rate)[46]<-"TSA_Frequency_Standard_Deviation"
names(rc_cortad_eco_rate)[47]<-"TSA_FrequencyMean"
names(rc_cortad_eco_rate)[48]<-"TSA_FrequencyMax"
names(rc_cortad_eco_rate)[51]<-"TSA_DHWMax"
names(rc_cortad_eco_rate)[52]<-"TSA_DHWMean"
names(rc_cortad_eco_rate)[53]<-"Region"
names(rc_cortad_eco_rate)[54]<-"Ecoregion_name"

#FIX THE NAMES, RECOUNT THE COLUMNS
colnames(rc_cortad_eco_rate)
rc_backup <- rc_cortad_eco_rate
rc_cortad_eco_rate_1 <- rc_cortad_eco_rate[,c("Reef.ID","Reef.Name","Ocean","Country","State.Province.Island", 
                                              "City.Town","Year","Date","Depth","Organism.Code","S1","S2","S3","S4",                                   
                                              "Errors.","What.errors.", "Average_bleaching","ClimSST","Temperature_Kelvin",                    
                                              "Temperature_Mean","Temperature_Minimum","Temperature_Maximum",                  
                                              "Temperature_Kelvin_Standard_Deviation","Windspeed","SSTA",                                  
                                              "SSTA_Standard_Deviation","SSTA_Mean","SSTA_Minimum",                        
                                              "SSTA_Maximum","SSTA_Frequency","SSTA_Frequency_Standard_Deviation",     
                                              "SSTA_FrequencyMax","SSTA_FrequencyMean","SSTA_DHW",                             
                                              "SSTA_DHW_Standard_Deviation","SSTA_DHWMax","SSTA_DHWMean","TSA",                                  
                                              "TSA_Standard_Deviation","TSA_Minimum","TSA_Maximum","TSA_Mean",                          
                                              "TSA_Frequency","TSA_Frequency_Standard_Deviation","TSA_FrequencyMax",
                                              "TSA_FrequencyMean","TSA_DHW","TSA_DHW_Standard_Deviation","TSA_DHWMax",
                                              "TSA_DHWMean","Region","Ecoregion_name","Diversity","rate_of_SST_change","Longitude.Degrees",                    
                                              "Latitude.Degrees")]

write.csv(rc_cortad_eco_rate_1,"final_rc_cer.csv", row.names=FALSE)

#clean NAs and add Bleached and Severity columns to RC ----
rc_new<-read.csv("final_rc_cer.csv")
pp<-read.csv("pp_data.csv")

#checking dataset for NAs, and data distribution
nrow(rc_new)
sum(is.na(rc_new$Longitude_degrees))
sum(is.na(rc_new$Errors.))
sum(is.na(rc_new$Average_bleaching))
sum(is.na(rc_new$Temperature_Kelvin))
sum(is.na(rc_new$Temperature_Mean))
sum(is.na(rc_new$SSTA))
sum(is.na(rc_new$SSTA_DHW))
sum(is.na(rc_new$TSA))
sum(is.na(rc_new$Ecoregion)) 
sum(is.na(rc_new$Diversity))
table(rc_new$Year)
table(rc_new$Ocean)

nrow(pp)
sum(is.na(pp$Longitude_degrees))
sum(is.na(pp$Average_bleaching))
sum(is.na(pp$Temperature_Kelvin))
sum(is.na(pp$Temperature_Mean))
sum(is.na(pp$SSTA))
sum(is.na(pp$SSTA_DHW))
sum(is.na(pp$TSA))
sum(is.na(pp$Ecoregion)) 
sum(is.na(pp$Diversity))
table(pp$Year)
table(pp$Ocean)

#exclude NA's
rc_cleaned <- rc_new[rowSums(is.na(rc_new[, intersect(c("Reef.ID","Reef.Name","Ocean","Country","State.Province.Island", 
                                                "City.Town","Year","Date","Depth","Organism.Code","S1","S2","S3","S4",
                                                "Average_bleaching","ClimSST","Temperature_Kelvin",
                                                "Temperature_Mean","Temperature_Minimum","Temperature_Maximum",
                                                "Temperature_Kelvin_Standard_Deviation","Windspeed","SSTA",
                                                "SSTA_Standard_Deviation","SSTA_Mean","SSTA_Minimum",
                                                "SSTA_Maximum","SSTA_Frequency","SSTA_Frequency_Standard_Deviation",
                                                "SSTA_FrequencyMax","SSTA_FrequencyMean","SSTA_DHW",
                                                "SSTA_DHW_Standard_Deviation","SSTA_DHWMax","SSTA_DHWMean","TSA",
                                                "TSA_Standard_Deviation","TSA_Minimum","TSA_Maximum","TSA_Mean",
                                                "TSA_Frequency","TSA_Frequency_Standard_Deviation","TSA_FrequencyMax",
                                                "TSA_FrequencyMean","TSA_DHW","TSA_DHW_Standard_Deviation","TSA_DHWMax",
                                                "TSA_DHWMean","Region","Ecoregion_name", "Diversity","rate_of_SST_change","Longitude.Degrees",
                                                "Latitude.Degrees"), names(rc_new))])) == 0, ]

sum(is.na(pp_cleaned))
sum(is.na(rc_cleaned))
sum(is.na(rc_cleaned$Errors.)) #NAs in Errors but it is okay because only surveys with values in S1,S2,S3,S4 were calculated for Avg_bleaching and others removed 

ocean_survey_counts <- table(rc_cleaned$Ocean)
ocean_survey_df <- as.data.frame(ocean_survey_counts)
colnames(ocean_survey_df) <- c("Ocean", "Total_Surveys")

eco_survey_counts <- table(rc_cleaned$Region)
eco_survey_df <- as.data.frame(eco_survey_counts)
colnames(eco_survey_df) <- c("Region", "Total_Surveys")

years_survey_counts <- table(rc_cleaned$Year)
years_survey_df <- as.data.frame(years_survey_counts)
colnames(years_survey_df) <- c("Year", "Total_Surveys")

rc_cleaned$Diversity <- as.numeric(rc_cleaned$Diversity)

#one survey with NA diversity after as.numeric function
rc_cleaned <- rc_cleaned[rowSums(is.na(rc_cleaned[, intersect(c("Reef.ID","Reef.Name","Ocean","Country","State.Province.Island", 
                                                        "City.Town","Year","Date","Depth","Organism.Code","S1","S2","S3","S4",
                                                        "Average_bleaching","ClimSST","Temperature_Kelvin",
                                                        "Temperature_Mean","Temperature_Minimum","Temperature_Maximum",
                                                        "Temperature_Kelvin_Standard_Deviation","Windspeed","SSTA",
                                                        "SSTA_Standard_Deviation","SSTA_Mean","SSTA_Minimum",
                                                        "SSTA_Maximum","SSTA_Frequency","SSTA_Frequency_Standard_Deviation",
                                                        "SSTA_FrequencyMax","SSTA_FrequencyMean","SSTA_DHW",
                                                        "SSTA_DHW_Standard_Deviation","SSTA_DHWMax","SSTA_DHWMean","TSA",
                                                        "TSA_Standard_Deviation","TSA_Minimum","TSA_Maximum","TSA_Mean",
                                                        "TSA_Frequency","TSA_Frequency_Standard_Deviation","TSA_FrequencyMax",
                                                        "TSA_FrequencyMean","TSA_DHW","TSA_DHW_Standard_Deviation","TSA_DHWMax",
                                                        "TSA_DHWMean","Ecoregion","Diversity","rate_of_SST_change","Longitude.Degrees",
                                                        "Latitude.Degrees"), names(rc_cleaned))])) == 0, ]
combined <- bind_rows(pp_cleaned, rc_cleaned)
write.csv(combined,"final_rc_combined.csv", row.names=FALSE)

combined <-read.csv("final_rc_combined.csv")
#at least 100 surveys per ecoregions, otherwise remove:
#combined_eco_survey_counts <- table(combined$Region)
#combined_eco_survey_df <- as.data.frame(combined_eco_survey_counts)
#colnames(combined_eco_survey_df) <- c("Region", "Total_Surveys")
#ecoregions_remove<- c("ERG004","ERG007", "ERG010","ERG012", "ERG021","ERG025", "ERG026",  
                      "ERG034", "ERG037" , "ERG041",
                      "ERG048", "ERG063", "ERG065", "ERG069", 
                      "ERG072", "ERG075", "ERG092","ERG094","ERG112","ERG114")

combined <- combined %>% 
  filter(!Region %in% ecoregions_remove)

#check if regions are removed
combined_eco_survey_counts_cleaned <- table(combined$Region)
combined_eco_survey_cleaned_df <- as.data.frame(combined_eco_survey_counts_cleaned)
colnames(combined_eco_survey_cleaned_df) <- c("Region", "Total_Surveys")

#check NAs:
sum(is.na(combined)) #908 (Errors. column)

#make columns for yes/no bleaching and severity of bleaching based on % -  
combined <- combined %>%
  mutate(Bleached = ifelse(Average_bleaching > 0, "Yes", "No"),
         Severity = case_when(
           Average_bleaching == 0 ~ "None",
           Average_bleaching > 0 & Average_bleaching <= 10 ~ "Mild",
           Average_bleaching > 10 & Average_bleaching <= 50 ~ "Moderate",
           Average_bleaching > 50 ~ "Severe",
         )) #scale taken from another paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC10552771/ 


combined<- combined %>% relocate(Bleached, Severity, .after = Average_bleaching)
write.csv(combined, "final_combined_severity.csv", row.names=FALSE )

#cw ecoregions and diversity:---- 
cw<-read.csv("cw_cortad_2022.csv")
diversity<-read.csv("Coral_diversity.csv")

ECO <- st_read(
  dsn   = "ecoregions_github", 
  layer = "ecoregion_exportPolygon"
)

ECO_noholes <- st_remove_holes(ECO)
print(ECO_noholes)

#extract geometry to rc
cw_eco <- st_as_sf(cw, 
                   coords = c("Longitude.Degrees", "Latitude.Degrees"), 
                   crs = 4326, 
                   remove = FALSE)

cw_eco <- st_transform(cw_eco, st_crs(ECO_noholes))
cw_joined <- st_join(cw_eco, ECO_noholes[, c("ERG", "Ecoregion")])

#fix errors: 
#ECO_noholes_valid <- st_make_valid(ECO_noholes)
#rc_joined <- st_join(rc_eco, ECO_noholes_valid[, c("ECO_CODE", "ECOREGION")])

#extracting div and eco part 2
cw_joined <- cw_joined %>%
  rename(Ecoregion_code = ERG) 

cw_joined$Ecoregion <- as.character(cw_joined$Ecoregion)
diversity$ECOREGION <- as.character(diversity$ECOREGION)

cw_joined$Ecoregion <- trimws(cw_joined$Ecoregion)
diversity$ECOREGION <- trimws(diversity$ECOREGION)

cw_joined <- cw_joined %>%
  left_join(diversity, by = c("Ecoregion" = "ECOREGION"))

#check for missing data
cw_joined <- cw_joined[!rowSums(is.na(cw_joined[, c("ClimSST", "Temperature_Kelvin", "Temperature_Mean", "Temperature_Minimum", "Temperature_Maximum", 
                                                    "Temperature_Kelvin_Standard_Deviation", "Windspeed",
                                                    "SSTA", "SSTA_Standard_Deviation", "SSTA_Mean", "SSTA_Minimum", "SSTA_Maximum", 
                                                    "SSTA_Freq", "SSTA_Freq_Standard_Deviation", "SSTA_Freq_Max", "SSTA_Freq_Mean", "SSTA_DHW", 
                                                    "SSTA_DHW_Standard_Deviation", "SSTA_DHW_Max", "SSTA_DHW_Mean", 
                                                    "TSA", "TSA_Standard_Deviation", "TSA_Mean", "TSA_Minimum", "TSA_Maximum", 
                                                    "TSA_Freq", "TSA_Freq_Standard_Deviation", "TSA_Freq_Mean", "TSA_Freq_Max", "TSA_DHW", 
                                                    "TSA_DHW_Standard_Deviation", "TSA_DHW_Max", "TSA_DHW_Mean")])), ]
sum(is.na(cw_joined$Diversity)) #586

unique(cw_joined$Ecoregion)
unique(diversity$ECOREGION)

sum(cw_joined$Ecoregion %in% diversity$ECOREGION)
mismatched_ecoregions <- cw_joined$Ecoregion[!cw_joined$Ecoregion %in% diversity$ECOREGION]
unique(mismatched_ecoregions)

#manually match unmatched ecoregions:
library(writexl)
write_xlsx(cw_joined, "cw_joined_manual_ecoregions.xlsx")

#load manually inputted NA ecoregions:
cw_joined<- read.csv("cw_ecoregions_diversity_manual.csv")

#code to fill in blank diversity values for these ecoregions:
cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Central and northern Great Barrier Reef" & is.na(Diversity),
    404,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Taiwan and coastal China" & is.na(Diversity),
    375,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Birds Head Peninsula, Papua" & is.na(Diversity),
    553,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Birds Head Peninsula, Papua" & is.na(Diversity),
    553,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Kenya and Tanzania coast" & is.na(Diversity),
    301,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Western Mexico and Revillagigedo Islands" & is.na(Diversity),
    34,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Lakshadweep Islands" & is.na(Diversity),
    141,
    Diversity
  ))

cw_joined<- cw_joined %>%
  mutate(Diversity = if_else(
    Ecoregion == "Milne Bay, Papua New Guinea" & is.na(Diversity),
    511,
    Diversity
  ))

#further cleaning to make everything consistent 
names(cw_cortad_eco_rate)[34]<-"SSTA_Frequency"
names(cw_cortad_eco_rate)[35]<-"SSTA_Frequency_Standard_Deviation"
names(cw_cortad_eco_rate)[36]<-"SSTA_FrequencyMax"
names(cw_cortad_eco_rate)[37]<-"SSTA_FrequencyMean"
names(cw_cortad_eco_rate)[40]<-"SSTA_DHWMax"
names(cw_cortad_eco_rate)[41]<-"SSTA_DHWMean"
names(cw_cortad_eco_rate)[47]<-"TSA_Frequency"
names(cw_cortad_eco_rate)[48]<-"TSA_Frequency_Standard_Deviation"
names(cw_cortad_eco_rate)[49]<-"TSA_FrequencyMean"
names(cw_cortad_eco_rate)[50]<-"TSA_FrequencyMax"
names(cw_cortad_eco_rate)[53]<-"TSA_DHWMax"
names(cw_cortad_eco_rate)[54]<-"TSA_DHWMean"
names(cw_cortad_eco_rate)[55]<-"Region"
names(cw_cortad_eco_rate)[56]<-"Ecoregion_name"

#FIX THE NAMES, RECOUNT THE COLUMNS
colnames(cw_cortad_eco_rate)
cw_backup <- cw_cortad_eco_rate
cw_cortad_eco_rate <- cw_cortad_eco_rate[,c("Reef.ID","Reef.Name","Ocean","Country","State.Province.Island", 
                                              "City.Town","Year","Date","Depth","Organism.Code","S1","S2","S3","S4",                                   
                                              "Errors.","What.errors.", "Average_bleaching","Bleached", "Severity", "ClimSST","Temperature_Kelvin",                    
                                              "Temperature_Mean","Temperature_Minimum","Temperature_Maximum",                  
                                              "Temperature_Kelvin_Standard_Deviation","Windspeed","SSTA",                                  
                                              "SSTA_Standard_Deviation","SSTA_Mean","SSTA_Minimum",                        
                                              "SSTA_Maximum","SSTA_Frequency","SSTA_Frequency_Standard_Deviation",     
                                              "SSTA_FrequencyMax","SSTA_FrequencyMean","SSTA_DHW",                             
                                              "SSTA_DHW_Standard_Deviation","SSTA_DHWMax","SSTA_DHWMean","TSA",                                  
                                              "TSA_Standard_Deviation","TSA_Minimum","TSA_Maximum","TSA_Mean",                          
                                              "TSA_Frequency","TSA_Frequency_Standard_Deviation","TSA_FrequencyMax",
                                              "TSA_FrequencyMean","TSA_DHW","TSA_DHW_Standard_Deviation","TSA_DHWMax",
                                              "TSA_DHWMean","Region","Ecoregion_name","Diversity","rate_of_SST_change","Longitude.Degrees",                    
                                              "Latitude.Degrees")]

write.csv(cw_cortad_eco_rate,"final_cw_cer.csv", row.names=FALSE)

#combiningn cw and rc
rm(list=ls())
#checking dataset for NAs, and data distribution
cw<-read.csv("final_cw_cer.csv")
nrow(cw)
sum(is.na(cw$Longitude_degrees))
sum(is.na(cw$Average_bleaching))
sum(is.na(cw$Temperature_Kelvin))
sum(is.na(cw$Temperature_Mean))
sum(is.na(cw$SSTA))
sum(is.na(cw$SSTA_DHW))
sum(is.na(cw$TSA))
sum(is.na(cw$Ecoregion)) 
sum(is.na(cw$Diversity))
table(cw$Year)
table(cw$Ocean)

#exclude NA's
cw_cleaned <- cw[rowSums(is.na(cw[, intersect(c("Reef.ID","Reef.Name","Country",
                                                        "Year","Date","Depth",
                                                        "Average_bleaching","Bleached","Severity","ClimSST","Temperature_Kelvin",
                                                        "Temperature_Mean","Temperature_Minimum","Temperature_Maximum",
                                                        "Temperature_Kelvin_Standard_Deviation","Windspeed","SSTA",
                                                        "SSTA_Standard_Deviation","SSTA_Mean","SSTA_Minimum",
                                                        "SSTA_Maximum","SSTA_Frequency","SSTA_Frequency_Standard_Deviation",
                                                        "SSTA_FrequencyMax","SSTA_FrequencyMean","SSTA_DHW",
                                                        "SSTA_DHW_Standard_Deviation","SSTA_DHWMax","SSTA_DHWMean","TSA",
                                                        "TSA_Standard_Deviation","TSA_Minimum","TSA_Maximum","TSA_Mean",
                                                        "TSA_Frequency","TSA_Frequency_Standard_Deviation","TSA_FrequencyMax",
                                                        "TSA_FrequencyMean","TSA_DHW","TSA_DHW_Standard_Deviation","TSA_DHWMax",
                                                        "TSA_DHWMean","Region","Ecoregion_name","Diversity","rate_of_SST_change","Longitude.Degrees",
                                                        "Latitude.Degrees"), names(cw))])) == 0, ]


sum(is.na(cw_cleaned$Region))
sum(is.na(cw_cleaned$Ecegion_name))
sum(is.na(cw_cleaned$Diversity))
sum(is.na(cw_cleaned$Errors.)) #NAs in Errors but it is okay because only surveys with values in S1,S2,S3,S4 were calculated for Avg_bleaching and others removed 

eco_survey_counts <- table(cw_cleaned$Region)
eco_survey_df <- as.data.frame(eco_survey_counts)
colnames(eco_survey_df) <- c("Region", "Total_Surveys")

years_survey_counts <- table(cw_cleaned$Year)
years_survey_df <- as.data.frame(years_survey_counts)
colnames(years_survey_df) <- c("Year", "Total_Surveys")

#match ocean names to cw:
unique_countries <- cw_cleaned %>%
  distinct(Country)

unique_reefname <- cw_cleaned %>%
  distinct(Reef.Name)

#change name "honduras" to "Honduras":
cw_cleaned <- cw_cleaned %>%
  mutate(Country = if_else(tolower(Country) == "honduras", "Honduras", Country))

#take Reef.Name to fill in missing location name columns:
cw_cleaned <- cw_cleaned %>%
  as_tibble() %>% 
  mutate(
    parts = str_split(Reef.Name, ",\\s*")
  ) %>%
  mutate(
    Country = map_chr(parts, ~ tail(.x, 1)),
    State.Province.Island = map_chr(parts, ~ if (length(.x) >= 3) .x[length(.x) - 1] else NA_character_),
    City.Town = map_chr(parts, ~ if (length(.x) >= 2) .x[2] else NA_character_)
  ) %>%
  dplyr::select(-parts)

#ocean, match with rc data:
cw_cleaned <- cw_cleaned %>%
  mutate(Ocean = case_when(
    Country == "United States of America" & str_detect(State.Province.Island, regex("Hawaii", ignore_case = TRUE)) ~ "Hawaii",
    Country == "United States of America" ~ "Atlantic",
    Country %in% c("Iran", "Kuwait", "United Arab Emirates", "Bahrain", "Oman") ~ "Arabian Gulf",
    Country == "Australia" & str_detect(State.Province.Island, regex("Cocos (Keeling) Islands", ignore_case = TRUE)) ~ "Indian",
    Country == "Australia" ~ "Pacific",
    Country %in% c("Egypt", "Eritrea", "Sudan", "Saudi Arabia") ~ "Red Sea",
    Country %in% c("Costa Rica") ~ "East Pacific",
    Country %in% c("Fiji", "Cook Islands", "Niue", "French Polynesia", 
                   "Northern Mariana Islands", "Japan", "Guam", 
                   "Micronesia", "Marshall Islands", "Papua New Guinea", "Tonga", 
                   "Vanuatu", "American Samoa", "Blue Buoy", "Hong Kong", "New Caledonia","Solomon Islands", "Taiwan") ~ "Pacific",
    Country %in% c("Honduras", "Belize", "Bahamas", "Nicaragua", 
                   "British Virgin Islands", "Cayman Islands", "Cuba", "Aruba", "Dominica",
                   "Dominican Republic", "Grenada", "Caribbean Netherlands", 
                   "Caribbean Netherlands (BES)", "Curacao", "Sint Maarten","St. Johns", "U.S. Virgin Islands","Jamaica",
                   "Brazil", "Turks and Caicos Islands", "Saint Vincent and the Grenadines", "Barbados", "Colombia", "Britsh Virgin Islands") ~ "Atlantic",
    Country %in% c("Mexico", "Ecuador", "Panama") ~ "Pacific",
    Country %in% c("Seychelles", "Mozambique", "India", "Mauritius", "Tanzania", 
                   "Madagascar", "Kenya", "Maldives", "South Africa") ~ "Indian",
    Country %in% c("Thailand", "Cambodia", "Malaysia", "Philippines", "Vietnam", "Indonesia", "Brunei", "Timor-Leste") ~ "Indo-Pacific"
  ))


#name source for each dataset 
rc <- rc %>%
  mutate(Source = "Reef Check")

cw_cleaned <- cw_cleaned %>%
  mutate(Source = "Coral Watch")

#combine rc and cw:
combined <- bind_rows(rc, cw_cleaned)
combined <- combined %>%
  relocate(Source, .before = Reef.ID)

write.csv(combined,"cw_rc_combined.csv", row.names=FALSE)
